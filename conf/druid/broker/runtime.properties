druid.service=broker
druid.port=9090

druid.server.http.numThreads=<HTTP_SERVER_THREADS>

druid.broker.http.unusedConnectionTimeout=<DRUID_BROKER_HTTP_UNUSED_CONNECTION_TIMEOUT>
druid.broker.http.readTimeout=<DRUID_BROKER_HTTP_READ_TIMEOUT>
druid.server.http.maxIdleTime=<DRUID_SERVER_HTTP_MAX_IDLE_TIME>
druid.broker.http.numConnections=<HTTP_CLIENT_CONNECTIONS>
druid.broker.http.maxQueuedBytes=<HTTP_MAX_QUEUED_BYTES>
druid.broker.balancer.type=<DRUID_BROKER_BALANCER_TYPE>
druid.broker.select.tier=<DRUID_BROKER_SELECT_TIER>
druid.broker.select.tier.custom.priorities=<DRUID_BROKER_SELECT_TIER_CUSTOM_PRIORITIES>
druid.server.http.defaultQueryTimeout=<DRUID_SERVER_HTTP_DEFAULT_QUERY_TIMEOUT>

# Query cache
druid.broker.cache.useCache=<DRUID_BROKER_CACHE_USE_CACHE>
druid.broker.cache.populateCache=<DRUID_BROKER_CACHE_POPULATE_CACHE>
druid.broker.cache.unCacheable=[]
druid.cache.type=caffeine
# TODO: Figure out good values for druid.cache.sizeInBytes and druid.cache.expireAfter

# Processing
druid.processing.buffer.sizeBytes=<PROCESSING_BUFFER_SIZEBYTES>
druid.processing.numMergeBuffers=<PROCESSING_NUM_MERGE_BUFFER>
druid.processing.numThreads=<THREADS>

druid.query.groupBy.maxOnDiskStorage=<GROUP_BY_MAX_ON_DISK_STORAGE>
druid.query.groupBy.intermediateCombineDegree=<GROUP_BY_INTERMEDIATE_COMBINE_DEGREE>
druid.query.groupBy.numParallelCombineThreads=<GROUP_BY_PARALLEL_COMBINE_THREADS>

# SQL
druid.sql.enable=true
druid.sql.planner.useApproximateCountDistinct=<USE_APPROXIMATE_COUNT_DISTINCT>
druid.sql.planner.useApproximateTopN=<USE_APPROXIMATE_TOPN>

druid.monitoring.monitors=["org.apache.druid.client.cache.CacheMonitor", "org.apache.druid.server.metrics.QueryCountStatsMonitor",\
  "org.apache.druid.java.util.metrics.JvmMonitor", "org.apache.druid.java.util.metrics.JvmCpuMonitor",\
   "org.apache.druid.java.util.metrics.JvmThreadsMonitor", "org.apache.druid.server.metrics.QueryBufferPoolStatsMonitor"]

druid.processing.fifo=true

# Parallel broker merge
druid.processing.merge.useParallelMergePool=<DRUID_PROCESSING_MERGE_USE_PARALLEL_MERGE_POOL>
druid.processing.merge.pool.parallelism=<DRUID_PROCESSING_MERGE_POOL_PARALLELISM>
druid.processing.merge.pool.defaultMaxQueryParallelism=<DRUID_PROCESSING_MERGE_POOL_DEFAULT_MAX_QUERY_PARALLELISM>
druid.processing.merge.pool.awaitShutdownMillis=<DRUID_PROCESSING_MERGE_POOL_AWAIT_SHUT_DOWN_MILLIS>
druid.processing.merge.task.targetRunTimeMillis=<DRUID_PROCESSING_MERGE_TASK_TARGET_RUN_TIME_MILLIS>
druid.processing.merge.task.initialYieldNumRows=<DRUID_PROCESSING_MERGE_TASK_INITIAL_YIELD_NUM_ROWS>
druid.processing.merge.task.smallBatchNumRows=<DRUID_PROCESSING_MERGE_TASK_SMALL_BATCH_NUM_ROWS>

# Processing options for exception
druid.processing.exception.skipRealtimeData=<DRUID_PROCESSING_EXCEPTION_SKIP_REALTIME_DATA>

druid.broker.segment.numThreadsToLoadSegmentSupplimentalIndexIntoShardSpec=<DRUID_BROKER_SEGMENT_NUM_THREADS_TO_LOAD_SEGMENT_SUPPLIMENTAL_INDEX_INTO_SHARD_SPEC>

# Logging
druid.request.logging.type=<DRUID_REQUEST_LOGGING_TYPE>
druid.request.logging.dir=/var/log/druid/requestlogs